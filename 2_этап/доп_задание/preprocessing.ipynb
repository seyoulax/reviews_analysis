{"cells":[{"cell_type":"code","source":["# !pip install nltk"],"metadata":{"id":"1kI9iBZJrpoF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ESN6tufb4_E5"},"outputs":[],"source":["import pandas as pd, numpy as np, re, json, ast, nltk, os\n","from string import punctuation\n","from tqdm import tqdm\n","import transformers\n","import torch"]},{"cell_type":"markdown","source":["# Delete"],"metadata":{"id":"fvYU_vXetqk_"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tAtwFNase6-E","outputId":"7acd4c7f-7d40-49c5-f0f4-4e9aa966b14d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# df = pd.read_csv('drive/MyDrive/sirius/reviews.csv')\n","\n","### вставить путь к датафрейму с отзывами\n","df = pd.read_csv('reviews_sravni.csv')\n","def process(text):\n","    text = text.replace('\\xa0', ' ')\n","    text = text.replace('\\n', ' ')\n","    return text\n","\n","df['text'] = df['text'].apply(process)\n","df['text'].values[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"ZidMfIvlciJj","outputId":"67f14103-b527-451e-9317-5a538e372c14"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Выражаю свою благодарность и признательность персональному менеджеру Ирине Р. Работали с ней в течении 1 года безупречно, съели ни один пуд настроек, отчетов, справок, выписок, открытие новых р/с, эквайрингов и прочее. Доступно объянит, быстро решит любой вопрос. Впрочем, как и всегда при обращении в банк, поддержка клиентов — одна из лучших. Наша организация является клиентом еще двух банков, так что есть с чем сравнить. Ирина — вы лучшая! Спасибо за работу! Желаю процветания и роста только ввысь!'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["reviews = df['text'].values.tolist()"],"metadata":{"id":"u0QiBNM_fyI9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# path='drive/MyDrive/sirius/data_banki_merged.json'\n","# data_without_labels_path='data_no_labels.txt'\n","# with open(data_without_labels_path, 'w') as f:\n","#   for sent in pd.read_json(path).iloc[:, 1].apply(lambda x: x['review']).values:\n","#     f.write(sent+'\\n')"],"metadata":{"id":"QjhEyUp5lJWn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with open('/content/data_no_labels.txt', 'r') as f:\n","#     reviews = f.readlines()\n","\n","# reviews = [line[:-1] for line in reviews]\n","# reviews = reviews\n","# reviews[0]"],"metadata":{"id":"04owvsbilVqg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Параметры обработки"],"metadata":{"id":"loA05IuflFck"}},{"cell_type":"code","source":["drop_stop_words = False # Удалить ли стоп-слова\n","drop_punctuation = True # Удалить ли пунктуацию\n","do_stemming = False # Применить ли стемминг\n","do_lemmatization = True # Применить ли лемматизацию\n","correct_punctuation = False # Исправить ли пунктуацию\n","\n","do_augmentation_bert = False # Использовать ли аугментацию с помощью BERT\n","do_augmentation_typos = False # Использовать ли аугментацию с помощью добавления опечаток\n","\n","# Что использовать для получения эмбеддингов\n","embedding_type = \"fasttext\" # @param [\"bert\", \"tf-idf\", \"word2wec\", \"fasttext\"]"],"metadata":{"id":"5UIPfN1vnghO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Requirements"],"metadata":{"id":"EmSHxsmb3tcz"}},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","stop_words = set(stopwords.words('russian'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7TEN5iXArYN_","outputId":"e9b3887f-3369-4ed5-93a8-c295eb0aa605"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["from nltk.stem import SnowballStemmer\n","stemmer = SnowballStemmer(\"russian\")"],"metadata":{"id":"awm-a-I1troh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if do_lemmatization:\n","    !pip install pymorphy2\n","    !pip install pymorphy2-dicts\n","    !pip install DAWG-Python\n","\n","    import pymorphy2\n","\n","    lemmatizer = pymorphy2.MorphAnalyzer()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ytoGk2a1wxQo","outputId":"5132d65e-754b-4384-c9bd-471c699d9166"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pymorphy2\n","  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy2)\n","  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n","Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n","  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docopt>=0.6 (from pymorphy2)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: docopt\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=c55c7204582f67e74168b288dfc7bbde830db328da093035bb21875c27997a2f\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","Successfully built docopt\n","Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n","Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n","Collecting pymorphy2-dicts\n","  Downloading pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pymorphy2-dicts\n","Successfully installed pymorphy2-dicts-2.4.393442.3710985\n","Requirement already satisfied: DAWG-Python in /usr/local/lib/python3.10/dist-packages (0.7.2)\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"iDPWv31-QEIT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if correct_punctuation:\n","    !pip install git+https://huggingface.co/kontur-ai/sbert_punc_case_ru\n","    from sbert_punc_case_ru import SbertPuncCase\n","    model_punct = SbertPuncCase().to(device)"],"metadata":{"id":"V7m6264e4WTz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Processing"],"metadata":{"id":"N77NOmFF3wOq"}},{"cell_type":"code","source":["def add_spaces(reviews):\n","  # add spaces if needed\n","  for iter in range(3):\n","    c, c_bad=len(reviews), 0\n","    for i, review in enumerate(reviews):\n","\n","      pattern=r'(\\w\\w[а-яё])([А-Я]\\w\\w)'    #Добавляем пробелы в нужных местах (по типу 'большойВвыбор')\n","      if re.search(pattern, review):\n","        c_bad+=1\n","        review=re.sub(pattern, r'\\1 \\2', review)\n","        reviews[i] = review\n","\n","    print(f'Итерация {iter}, всего отзывов {c}, в {c_bad} добавлены пробелы')\n","  return reviews\n","\n","reviews = add_spaces(reviews)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iG5h9t4rnvea","outputId":"1db4db68-aba5-4023-9b25-8385ce737db1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Итерация 0, всего отзывов 10000, в 62 добавлены пробелы\n","Итерация 1, всего отзывов 10000, в 3 добавлены пробелы\n","Итерация 2, всего отзывов 10000, в 0 добавлены пробелы\n"]}]},{"cell_type":"code","source":["# точка, запятая - не трогать, если по бокам цифры; иначе пробелы добавить (если не повторяются, '...' тоже не трогаем)\n","# остальные - добавить пробелы по бокам, если не повторяются (по типу !!!)\n","\n","def process_punctuation(reviews, drop_punctuation=False, correct_punctuation=False):\n","  # Обрабатываем знаки препинания\n","\n","    for i, review in enumerate(reviews):\n","\n","        if drop_punctuation or correct_punctuation:\n","            review = re.sub(rf'[{punctuation}]', ' ', review) # Удаляем всю пунктуацию\n","            continue\n","\n","\n","        review= re.sub(rf'(\\W)', rf' \\1 ', review) # Банк,плохой -> Банк , плохой\n","        review = re.sub(rf'\\s+', rf' ', review) # Банк    ,    плохой -> Банк , плохой\n","\n","        for punct in '.,':\n","            review = re.sub(rf'([\\d\\{punct}]) (\\{punct}) ([\\d\\{punct}])', rf'\\1\\2\\3', review) # 1 , 5 -> 1,5 или . . . -> ...\n","\n","        for punct in punctuation:\n","            review = re.sub(rf'(\\{punct}) (\\{punct}) (\\{punct})', rf'\\1\\2\\3', review) # ! ! ! -> !!!\n","\n","        reviews[i] = review\n","\n","    print(reviews[0].split()[:10])\n","    return reviews\n","\n","reviews = process_punctuation(reviews, drop_punctuation, correct_punctuation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sbvcwMzjok9Q","outputId":"f0d12adf-8a48-490f-eb4e-a0e43808bc99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Выражаю', 'свою', 'благодарность', 'и', 'признательность', 'персональному', 'менеджеру', 'Ирине', 'Р.', 'Работали']\n"]}]},{"cell_type":"code","source":["def process_stop_words(reviews, stop_words):\n","    # Удаляем стоп-слова\n","\n","    for i, review in enumerate(reviews):\n","        review = [word for word in review.split() if word.lower() not in stop_words]\n","        review = ' '.join(review)\n","        reviews[i] = review\n","\n","    print(reviews[0].split()[:10])\n","    return reviews\n","\n","if drop_stop_words:\n","    reviews = process_stop_words(reviews, stop_words)"],"metadata":{"id":"lg6C44cpqsNg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Стемминг"],"metadata":{"id":"1s1Q-WtGPg5x"}},{"cell_type":"code","source":["def stemming(reviews, stemmer):\n","    # Применяем стемминг\n","\n","    for i, review in tqdm(enumerate(reviews)):\n","        review = [stemmer.stem(word) for word in review.split()]\n","        reviews[i] = ' '.join(review)\n","\n","    print(reviews[0].split()[:10])\n","    return reviews\n","\n","if do_stemming:\n","    reviews = stemming(reviews, stemmer)"],"metadata":{"id":"OliU40h0s9lY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Лемматизация"],"metadata":{"id":"PNzPO1pQPjqr"}},{"cell_type":"code","source":["def lemmatization(reviews, lemmatizer):\n","    # Применяем лемматизацию\n","\n","    for i, review in tqdm(enumerate(reviews)):\n","        review = [lemmatizer.parse(word)[0].normal_form for word in review.split()]\n","        reviews[i] = ' '.join(review)\n","\n","    print(reviews[0].split()[:10])\n","    return reviews\n","\n","if do_lemmatization:\n","    reviews = lemmatization(reviews, lemmatizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_Xdob00v8FL","outputId":"299a7920-671e-4ff0-81a5-81a40c24d242"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["10000it [03:38, 45.71it/s]"]},{"output_type":"stream","name":"stdout","text":["['выражать', 'свой', 'благодарность', 'и', 'признательность', 'персональный', 'менеджер', 'ирина', 'р.', 'работать']\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## Правка пунктуации"],"metadata":{"id":"nGV5tLnNPlSx"}},{"cell_type":"code","source":["def punctuation_correction(reviews, model_punct, device):\n","    # Правим пунтуацию\n","    model_punct.to(device)\n","\n","    for i, review in tqdm(enumerate(reviews)):\n","        review = model_punct.punctuate(review)\n","        reviews[i] = review\n","\n","    return reviews\n","\n","if correct_punctuation:\n","    reviews = punctuation_correction(reviews, model_punct, device)"],"metadata":{"id":"HTGOknTGyQgE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Аугментация"],"metadata":{"id":"xKR_k5aJPoXG"}},{"cell_type":"code","source":["def softmax(z):\n","    exp_z = np.exp(z)\n","    softmax_probs = exp_z / np.sum(exp_z, axis=0)\n","    return softmax_probs\n","\n","def augment_data(reviews, do_augmentation_typos, do_augmentation_bert, fill_mask, tokenizer):\n","    prob_bert = 0.15 # Сколько слов заменяем с помощью BERT\n","    prob_typos = 0.15 # Сколько слов заменяем с помощью опечаток\n","\n","    reviews_augmented = []\n","\n","    for i, review in tqdm(enumerate(reviews)):\n","        if len(tokenizer.encode(review)) > 512:\n","            is_too_long=True\n","        else:\n","            is_too_long=False\n","        flag_review_changed = 0\n","\n","        words = review.split()\n","\n","        for j, word in enumerate(words):\n","            if word.isalnum() == False or word.isdigit(): # Цифры и пунктуацию не трогаем\n","                continue\n","\n","            if do_augmentation_typos and do_augmentation_bert:\n","                choice = np.random.choice(3, 1, p=[1-prob_typos-prob_bert, prob_bert, prob_typos])[0] # 0 - пропуск, 1 - BERT, 2 - опечатка\n","            elif do_augmentation_typos:\n","                choice = np.random.choice(3, 1, p=[1-prob_typos, prob_typos])[0]\n","                if choice == 1:\n","                    choice = 2\n","            elif do_augmentation_bert:\n","                choice = np.random.choice(3, 1, p=[1-prob_bert, prob_bert])[0]\n","\n","\n","            if choice == 1:\n","                if is_too_long : continue # Слишком длинная последовательность\n","                words[i] = '[MASK]'\n","                for result in fill_mask(' '.join(words)):\n","                    if result['token_str'] != word and result['score']>=0.1: # Берем, если вероятность выше 0.1\n","                        flag_review_changed = 1\n","                        words[i] = result['token_str'] # Заменяем слово на новое\n","                        break\n","                else:\n","                    words[i] = word # Возвращаем слово на место\n","\n","            elif choice == 2 and word in all_words:\n","                flag_review_changed = 1\n","                subset = mistakes.loc[mistakes['CORRECT']==word]\n","                p = softmax(subset.WEIGHT.values) # Вероятности ошибок\n","                new_word = subset.iloc[np.random.choice(np.arange(len(subset)), 1, p=p)[0], 1]\n","                words[i] = new_word\n","\n","        review = ' '.join(words)\n","        if not flag_review_changed:\n","            reviews_augmented.append('')\n","        else:\n","            reviews_augmented.append(review)\n","\n","    return reviews_augmented\n","\n","\n","if do_augmentation_bert or do_augmentation_typos:\n","\n","    from transformers import pipeline\n","\n","    mistakes = pd.read_csv('https://raw.githubusercontent.com/dkulagin/kartaslov/master/dataset/orfo_and_typos/orfo_and_typos.L1_5.csv', sep=';')\n","    all_words = set(mistakes['CORRECT'].unique())\n","\n","    tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruBert-base\", truncation=True, max_length=512)\n","\n","    fill_mask = pipeline('fill-mask', 'ai-forever/ruBert-base', tokenizer=tokenizer, device=device)\n","\n","\n","    reviews_augmented = augment_data(reviews, do_augmentation_typos, do_augmentation_bert, fill_mask, tokenizer)\n","\n"],"metadata":{"id":"_yNaxW1b91U_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Получение эмбеддингов"],"metadata":{"id":"qMeJvvKDPr-o"}},{"cell_type":"markdown","source":["### TF-IDF"],"metadata":{"id":"IIXH_G96QeZM"}},{"cell_type":"code","source":["if embedding_type == 'tf-idf':\n","    from sklearn.feature_extraction.text import TfidfVectorizer\n","    max_df = 100 # Максимальная встречаемость слова\n","    min_df = 10 # Минимальная встречаемость слова\n","    vectorizer = TfidfVectorizer(input='content', max_df=max_df, min_df=min_df)\n","\n","    embeddings = vectorizer.fit_transform(reviews)\n","    embeddings = embeddings.toarray()\n","    print(embeddings.shape)"],"metadata":{"id":"59NGXTenRHmW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Word2vec"],"metadata":{"id":"PgoEngrVTBhO"}},{"cell_type":"code","source":["def get_sentence_embedding(sentence, model):\n","    words = sentence.split()\n","    word_embeddings=[]\n","    for word in words:\n","        try:\n","            word_embeddings.append(model.wv.word_vec(word))\n","        except KeyError:\n","            pass\n","    if word_embeddings:\n","        return sum(word_embeddings) / len(word_embeddings) # Усредняем эмбеддинги слов в отзыве\n","    else:\n","        return None\n","\n","\n","if embedding_type == 'word2wec':\n","\n","    !pip install gensim\n","\n","    from gensim.models import Word2Vec\n","\n","    w2v_model = Word2Vec(\n","        min_count=10,\n","        window=2,\n","        vector_size=300,\n","        negative=10,\n","        alpha=0.03,\n","        min_alpha=0.0007,\n","        sample=6e-5,\n","        sg=1)\n","\n","    data = pd.Series([review.split() for review in reviews])\n","\n","    w2v_model.build_vocab(data)\n","\n","    embeddings = []\n","    for review in reviews:\n","        embeddings.append(get_sentence_embedding(review, w2v_model))\n","\n","    embeddings = np.array(embeddings)\n","    print(embeddings.shape)"],"metadata":{"id":"VhZ6D9QsTDgi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### fastText"],"metadata":{"id":"Trvf1QrLTJ51"}},{"cell_type":"code","source":["def get_sentence_embedding(sentence, model):\n","    words = sentence.split()\n","    word_embeddings=[]\n","    for word in words:\n","        try:\n","            word_embeddings.append(model[word])\n","        except KeyError:\n","            pass\n","    if word_embeddings:\n","        return sum(word_embeddings) / len(word_embeddings) # Усредняем эмбеддинги слов в отзыве\n","    else:\n","        return None\n"],"metadata":{"id":"n6q4GEXMb4DG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if embedding_type == 'fasttext':\n","    !pip install fasttext\n","\n","    import fasttext\n","    from huggingface_hub import hf_hub_download\n","\n","    model_path = hf_hub_download(repo_id=\"facebook/fasttext-ru-vectors\", filename=\"model.bin\")\n","    model = fasttext.load_model(model_path)\n","\n","    embeddings = []\n","    for review in reviews:\n","        embeddings.append(get_sentence_embedding(review, model))\n","\n","    embeddings = np.array(embeddings)\n","    print(embeddings.shape)"],"metadata":{"id":"lrGgi0L2TO33","colab":{"base_uri":"https://localhost:8080/","height":489,"referenced_widgets":["351c10015e654c2582bf182b0fde42aa","b69c388b5de14f9384e4f871baed7a53","2482635c139345fc83821dd68e0058b2","74c97e20d76342fdb91273b3fcd12a80","2343ddb468db4a7f81d805f71cb28891","b60bfceceaf04cdeb40d3e9e2790c87c","6cb6cb33e9784bf8bd0bb497b4260a0f","b3d8a3d009fa4ac6a24628b5c99a613b","1eba02ba928d4d9eb8316cf5d20c47b2","e174c5a4a17d461e907d670964cfb67c","e2d5e3e2eaa942d484582347f356b85b"]},"outputId":"af299c77-ece6-4bd2-ecf7-0bf28d4cc99a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fasttext\n","  Downloading fasttext-0.9.2.tar.gz (68 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pybind11>=2.2 (from fasttext)\n","  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199770 sha256=b3ebae8b9f2c24bebdfcfae84a77e1c78643277e968a435a3925f579ddbfa50e\n","  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n","Successfully built fasttext\n","Installing collected packages: pybind11, fasttext\n","Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.bin:   0%|          | 0.00/7.26G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"351c10015e654c2582bf182b0fde42aa"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"]},{"output_type":"stream","name":"stdout","text":["(10000, 300)\n"]}]},{"cell_type":"markdown","source":["### BERT"],"metadata":{"id":"EU-tavYCTLt0"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModel\n","\n","\n","def mean_pooling(model_output, attention_mask):\n","    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n","    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n","    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","    return sum_embeddings / sum_mask\n","\n","\n","if embedding_type == 'bert':\n","\n","\n","    tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")\n","    model = AutoModel.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")\n","\n","    model.to(device)\n","\n","    embeddings = []\n","\n","    for review in tqdm(reviews):\n","\n","        encoded_input = tokenizer(review, padding=False, truncation=True, max_length=512, return_tensors='pt').to(device)\n","\n","        with torch.no_grad():\n","            model_output = model(**encoded_input)\n","\n","        embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n","        embeddings.append(embedding[0])\n","\n","    embeddings = torch.stack(embeddings).cpu().numpy()\n","\n"],"metadata":{"id":"m97ezY2JTXL6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Сохраним эмбеддинги"],"metadata":{"id":"dlomiOv3c-Fq"}},{"cell_type":"code","source":["embeddings = pd.DataFrame(embeddings)\n","embeddings.columns = [str(col) for col in embeddings.columns]\n","# embeddings.to_parquet('drive/MyDrive/sirius/embeddings_reviews_word2vec_sravni.parquet')\n","embeddings.to_parquet('drive/MyDrive/sirius/embeddings_reviews_fasttext_sravni.parquet')"],"metadata":{"id":"XFMdeKJGdAQz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"k4FcReg107Wd"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"351c10015e654c2582bf182b0fde42aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b69c388b5de14f9384e4f871baed7a53","IPY_MODEL_2482635c139345fc83821dd68e0058b2","IPY_MODEL_74c97e20d76342fdb91273b3fcd12a80"],"layout":"IPY_MODEL_2343ddb468db4a7f81d805f71cb28891"}},"b69c388b5de14f9384e4f871baed7a53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b60bfceceaf04cdeb40d3e9e2790c87c","placeholder":"​","style":"IPY_MODEL_6cb6cb33e9784bf8bd0bb497b4260a0f","value":"model.bin: 100%"}},"2482635c139345fc83821dd68e0058b2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3d8a3d009fa4ac6a24628b5c99a613b","max":7255753778,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1eba02ba928d4d9eb8316cf5d20c47b2","value":7255753778}},"74c97e20d76342fdb91273b3fcd12a80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e174c5a4a17d461e907d670964cfb67c","placeholder":"​","style":"IPY_MODEL_e2d5e3e2eaa942d484582347f356b85b","value":" 7.26G/7.26G [02:34&lt;00:00, 48.7MB/s]"}},"2343ddb468db4a7f81d805f71cb28891":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b60bfceceaf04cdeb40d3e9e2790c87c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cb6cb33e9784bf8bd0bb497b4260a0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3d8a3d009fa4ac6a24628b5c99a613b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1eba02ba928d4d9eb8316cf5d20c47b2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e174c5a4a17d461e907d670964cfb67c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2d5e3e2eaa942d484582347f356b85b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}